{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\n# 53907afe-531b-11ea-a595-00505601122b\n# b7ea974c-d389-11e8-a4be-00505601122b","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-13T11:23:39.091409Z","iopub.execute_input":"2022-04-13T11:23:39.092115Z","iopub.status.idle":"2022-04-13T11:23:39.108066Z","shell.execute_reply.started":"2022-04-13T11:23:39.092007Z","shell.execute_reply":"2022-04-13T11:23:39.107538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Setup","metadata":{}},{"cell_type":"markdown","source":"## 1.1 FS/OS requirements","metadata":{}},{"cell_type":"code","source":"!cp /kaggle/input/tagger-competition/morpho_analyzer.py /kaggle/working/morpho_analyzer.py\n!cp /kaggle/input/tagger-competition/morpho_dataset.py /kaggle/working/morpho_dataset.py\n!cp /kaggle/input/tagger-competition/czech_pdt.zipnot /kaggle/working/czech_pdt.zip\n!cp /kaggle/input/tagger-competition/czech_pdt_analyses.zipnot /kaggle/working/czech_pdt_analyses.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-13T11:24:09.942383Z","iopub.execute_input":"2022-04-13T11:24:09.942696Z","iopub.status.idle":"2022-04-13T11:24:13.256123Z","shell.execute_reply.started":"2022-04-13T11:24:09.942658Z","shell.execute_reply":"2022-04-13T11:24:13.254815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install -U tensorflow-gpu==2.8 tensorflow-addons==0.16.1 tensorflow-probability==0.16.0 tensorflow-hub==0.12.0 scipy\n!pip freeze | grep tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-04-13T11:24:22.810472Z","iopub.execute_input":"2022-04-13T11:24:22.810764Z","iopub.status.idle":"2022-04-13T11:24:25.179121Z","shell.execute_reply.started":"2022-04-13T11:24:22.810733Z","shell.execute_reply":"2022-04-13T11:24:25.178419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 Python imports","metadata":{}},{"cell_type":"code","source":"import argparse\nimport datetime\nimport os\nimport re\n\nos.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport fasttext\nimport fasttext.util\n\nfrom morpho_analyzer import MorphoAnalyzer\nfrom morpho_dataset import MorphoDataset","metadata":{"execution":{"iopub.status.busy":"2022-04-13T11:24:30.349098Z","iopub.execute_input":"2022-04-13T11:24:30.349358Z","iopub.status.idle":"2022-04-13T11:24:36.634256Z","shell.execute_reply.started":"2022-04-13T11:24:30.34933Z","shell.execute_reply":"2022-04-13T11:24:36.63369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.3 Fasttext model","metadata":{}},{"cell_type":"code","source":"fasttext.util.download_model('cs', if_exists='ignore')  # English\nft = fasttext.load_model('cc.cs.300.bin')","metadata":{"execution":{"iopub.status.busy":"2022-04-13T11:24:44.609596Z","iopub.execute_input":"2022-04-13T11:24:44.610283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.4 Args","metadata":{}},{"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument(\"--batch_size\", default=None, type=int, help=\"Batch size.\")\nparser.add_argument(\"--epochs\", default=None, type=int, help=\"Number of epochs.\")\nparser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\nparser.add_argument(\"--threads\", default=1, type=int, help=\"Maximum number of threads to use.\")\nparser.add_argument(\"--checkpoints_period\", default=None, type=int, help=\"Checkpoint callback period.\")\nparser.add_argument(\"--stopping_patience\", default=None, type=int, help=\"Early stopping epochs patience.\")\nparser.add_argument(\"--cle_dim\", default=32, type=int, help=\"CLE embedding dimension.\")\nparser.add_argument(\"--max_sentences\", default=None, type=int, help=\"Maximum number of sentences to load.\")\nparser.add_argument(\"--word_masking\", default=0.0, type=float, help=\"Mask words with the given probability.\")\nparser.add_argument(\"--label_smoothing\", default=None, type=float, help=\"\")\nparser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Initial model learning rate.\")\n\nargs = parser.parse_args([\n    '--batch_size=256',\n    '--epochs=10',\n    '--checkpoints_period=3',\n    '--stopping_patience=3',\n    '--learning_rate=0.01'\n] if \"__file__\" not in globals() else None)\n\n# Create logdir name\nargs.logdir = os.path.join(\n    \"logs\",\n    \"{}-{}-{}\".format(\n        os.path.basename(globals().get(\"__file__\", \"notebook\")),\n        datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"),\n        \",\".join(\n            (\n                \"{}={}\".format(re.sub(\"(.)[^_]*_?\", r\"\\1\", k), v)\n                for k, v in sorted(vars(args).items())\n            )\n        ),\n    ),\n)\n\ntf.random.set_seed(args.seed) # tf2.6 (I have gpu issues on tf2.8 unfortunately)\ntf.config.threading.set_inter_op_parallelism_threads(args.threads)\ntf.config.threading.set_intra_op_parallelism_threads(args.threads)\n\nargs","metadata":{"execution":{"iopub.status.busy":"2022-04-13T10:29:22.669886Z","iopub.execute_input":"2022-04-13T10:29:22.670199Z","iopub.status.idle":"2022-04-13T10:29:22.695044Z","shell.execute_reply.started":"2022-04-13T10:29:22.670169Z","shell.execute_reply":"2022-04-13T10:29:22.694147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args.decay_steps = int(args.epochs * morpho.train.size / args.batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T10:05:10.563963Z","iopub.execute_input":"2022-04-13T10:05:10.564222Z","iopub.status.idle":"2022-04-13T10:05:10.568408Z","shell.execute_reply.started":"2022-04-13T10:05:10.564193Z","shell.execute_reply":"2022-04-13T10:05:10.567697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data","metadata":{}},{"cell_type":"code","source":"morpho = MorphoDataset(\"czech_pdt\")\n# analyses = MorphoAnalyzer(\"czech_pdt_analyses\")\n\nTAGS_NUM = morpho.train.tags.word_mapping.vocabulary_size()\nargs.decay_steps = int(args.epochs * morpho.train.size / args.batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T08:45:45.7827Z","iopub.execute_input":"2022-04-13T08:45:45.782948Z","iopub.status.idle":"2022-04-13T08:46:00.111948Z","shell.execute_reply.started":"2022-04-13T08:45:45.782923Z","shell.execute_reply":"2022-04-13T08:46:00.111095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_tagging_data(example):\n    return (example[\"forms\"], morpho.train.tags.word_mapping(example[\"tags\"]))\n\ndef to_categorical(form, tag):\n    return (form, tf.one_hot(tag, TAGS_NUM))\n    \ndef create_dataset(name):\n    dataset = getattr(morpho, name).dataset\n    dataset = dataset.map(extract_tagging_data)\n    if args.label_smoothing:\n        dataset = dataset.map(to_categorical)\n    dataset = (\n        dataset.shuffle(len(dataset), seed=args.seed)\n        if name == \"train\"\n        else dataset\n    )\n    dataset = dataset.apply(\n        tf.data.experimental.dense_to_ragged_batch(args.batch_size)\n    )\n    return dataset\n\ntrain, dev = create_dataset(\"train\"), create_dataset(\"dev\")","metadata":{"execution":{"iopub.status.busy":"2022-04-13T10:05:14.977916Z","iopub.execute_input":"2022-04-13T10:05:14.978509Z","iopub.status.idle":"2022-04-13T10:05:15.434457Z","shell.execute_reply.started":"2022-04-13T10:05:14.978468Z","shell.execute_reply":"2022-04-13T10:05:15.433683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tags_stats = morpho.train.tags.word_mapping(np.array([item for sublist in morpho.train.tags.strings for item in sublist]))\nfiltered_tags_stats = tags_stats[tags_stats < len(np.unique(tags_stats))] # Filtered tags without the last (most frequent) tag\nlen(tags_stats), len(filtered_tags_stats)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T17:39:36.727907Z","iopub.status.idle":"2022-04-12T17:39:36.728705Z","shell.execute_reply.started":"2022-04-12T17:39:36.728445Z","shell.execute_reply":"2022-04-12T17:39:36.728471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.histplot(tags_stats, discrete=True, kde=True, stat=\"count\").set_title(\"Tags histogram (including last class)\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:14:23.067408Z","iopub.execute_input":"2022-04-12T15:14:23.068455Z","iopub.status.idle":"2022-04-12T15:14:32.994129Z","shell.execute_reply.started":"2022-04-12T15:14:23.068388Z","shell.execute_reply":"2022-04-12T15:14:32.99354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.histplot(filtered_tags_stats, discrete=True, kde=True, stat=\"count\").set_title(\"Tags histogram (excluding last class)\")","metadata":{"execution":{"iopub.status.busy":"2022-04-12T15:14:37.94746Z","iopub.execute_input":"2022-04-12T15:14:37.948264Z","iopub.status.idle":"2022-04-12T15:14:47.342448Z","shell.execute_reply.started":"2022-04-12T15:14:37.948222Z","shell.execute_reply":"2022-04-12T15:14:47.341518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"code","source":"# idea taken from https://piazza.com/class/kzmwighamh26wd?cid=284\ndef fasttext_eager(inputs):\n    return np.array([self.ft.get_word_vector(w) for w in inputs])\n\nclass Model(tf.keras.Model):\n\n    def __init__(self, args: argparse.Namespace, train: MorphoDataset.Dataset) -> None:\n        words = tf.keras.layers.Input(shape=[None], dtype=tf.string, ragged=True)\n        #unique_words, unique_words_idx = tf.unique(words.values)\n        #letter_seqs = tf.strings.unicode_split(unique_words, \"UTF-8\")\n        #letter_ids = train.forms.char_mapping(letter_seqs)\n        #char_embedding = tf.keras.layers.Embedding(train.forms.char_mapping.vocabulary_size(), 32)(letter_ids)\n        #cle_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32), merge_mode=\"concat\")(char_embedding)\n        #hey = tf.gather(cle_gru, unique_words_idx)\n        #cle_embedding = words.with_values(hey)\n        \n        embedding = tf.numpy_function(func=fasttext_eager, inp=[words.values], Tout=tf.float32)\n        embedding = words.with_values(tf.ensure_shape(embedding, (None, ft.get_dimension())))\n\n        sequences = tf.keras.layers.Bidirectional(\n            tf.keras.layers.RNN(tfa.rnn.LayerNormLSTMCell(64, recurrent_dropout=0.3), return_sequences=True, return_state=False), merge_mode=\"sum\"\n        )(embedding)\n        \n        hidden = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation=None))(tf.keras.layers.Concatenate()([embedding, sequences]))\n        hidden = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(hidden)\n        hidden = tf.keras.layers.TimeDistributed(tf.keras.layers.Activation(\"swish\"))(hidden)\n        hidden = tf.keras.layers.Dropout(.3)(hidden)\n        \n        predictions = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n            train.tags.word_mapping.vocabulary_size(), activation=\"softmax\"\n        ))(hidden)\n\n        super().__init__(inputs=words, outputs=predictions)\n        \n        if args.label_smoothing:\n            loss = lambda yt, yp: tf.losses.CategoricalCrossentropy(label_smoothing=args.label_smoothing)(yt.values, yp.values)\n            metrics = [tf.metrics.CategoricalAccuracy(name=\"accuracy\")]\n        else:\n            loss = lambda yt, yp: tf.losses.SparseCategoricalCrossentropy()(yt.values, yp.values)\n            metrics = [tf.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n            \n        self.compile(\n            optimizer=tf.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.CosineDecay(args.learning_rate, args.decay_steps)),\n            loss=loss,\n            metrics=metrics,\n        )\n\n        self.callbacks = list()\n        self.tb_callback = tf.keras.callbacks.TensorBoard(args.logdir)\n        self.callbacks.append(self.tb_callback)\n        if args.checkpoints_period:\n            self.checkpoints = tf.keras.callbacks.ModelCheckpoint('weights{epoch:08d}.h5', save_weights_only=True, period=args.checkpoints_period) \n            self.callbacks.append(self.checkpoints)\n        if args.stopping_patience:\n            self.early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=args.stopping_patience)\n            self.callbacks.append(self.early_stopping)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T09:33:28.797581Z","iopub.execute_input":"2022-04-13T09:33:28.797963Z","iopub.status.idle":"2022-04-13T09:33:28.820573Z","shell.execute_reply.started":"2022-04-13T09:33:28.797929Z","shell.execute_reply":"2022-04-13T09:33:28.818449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(args, morpho.train)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-13T09:33:33.49767Z","iopub.execute_input":"2022-04-13T09:33:33.49793Z","iopub.status.idle":"2022-04-13T09:33:35.524252Z","shell.execute_reply.started":"2022-04-13T09:33:33.497903Z","shell.execute_reply":"2022-04-13T09:33:35.523552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logs = model.fit(\n    train, \n    epochs=args.epochs,\n    validation_data=dev,\n    shuffle=True,\n    callbacks=[model.callbacks],\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-13T10:05:24.763676Z","iopub.execute_input":"2022-04-13T10:05:24.764149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = create_dataset(\"test\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(args.logdir, exist_ok=True)\nwith open(\n    os.path.join(args.logdir, \"tagger_competition.txt\"), \"w\", encoding=\"utf-8\"\n) as predictions_file:\n    # TODO: Predict the tags on the test set; update the following prediction\n    # command if you use other output structre than in tagger_we.\n    predictions = model.predict(test)\n    tag_strings = morpho.test.tags.word_mapping.get_vocabulary()\n    for sentence in predictions:\n        for word in sentence:\n            print(tag_strings[np.argmax(word)], file=predictions_file)\n        print(file=predictions_file)","metadata":{},"execution_count":null,"outputs":[]}]}