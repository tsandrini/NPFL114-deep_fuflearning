{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!/usr/bin/env python3\n# 53907afe-531b-11ea-a595-00505601122b\n# b7ea974c-d389-11e8-a4be-00505601122b","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-11T14:42:18.725289Z","iopub.execute_input":"2022-05-11T14:42:18.726022Z","iopub.status.idle":"2022-05-11T14:42:18.729914Z","shell.execute_reply.started":"2022-05-11T14:42:18.725985Z","shell.execute_reply":"2022-05-11T14:42:18.729230Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 1. Setup","metadata":{}},{"cell_type":"markdown","source":"## 1.1. FS/OS Requirements","metadata":{}},{"cell_type":"code","source":"!cp /kaggle/input/homr-competition/homr_dataset.py /kaggle/working/homr_dataset.py\n!cp /kaggle/input/homr-competition/homr.train.tfrecord /kaggle/working/homr.train.tfrecord\n!cp /kaggle/input/homr-competition/homr.test.tfrecord /kaggle/working/homr.test.tfrecord\n!cp /kaggle/input/homr-competition/homr.dev.tfrecord /kaggle/working/homr.dev.tfrecord","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:13:03.988903Z","iopub.execute_input":"2022-05-12T05:13:03.989641Z","iopub.status.idle":"2022-05-12T05:13:12.238693Z","shell.execute_reply.started":"2022-05-12T05:13:03.989547Z","shell.execute_reply":"2022-05-12T05:13:12.237781Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#!pip install -U tensorflow-gpu==2.8 tensorflow-addons==0.16.1 tensorflow-probability==0.16.0 tensorflow-hub==0.12.0 scipy\n!pip freeze | grep tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-05-11T14:37:10.824408Z","iopub.execute_input":"2022-05-11T14:37:10.825120Z","iopub.status.idle":"2022-05-11T14:37:14.702892Z","shell.execute_reply.started":"2022-05-11T14:37:10.825076Z","shell.execute_reply":"2022-05-11T14:37:14.702044Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Python imports","metadata":{}},{"cell_type":"code","source":"import argparse\nimport datetime\nimport functools\nimport os\nimport re\n\nos.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom homr_dataset import HOMRDataset","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:44:58.997615Z","iopub.execute_input":"2022-05-12T05:44:58.998118Z","iopub.status.idle":"2022-05-12T05:45:05.173103Z","shell.execute_reply.started":"2022-05-12T05:44:58.998067Z","shell.execute_reply":"2022-05-12T05:45:05.172382Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## 1.3. Args","metadata":{}},{"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument(\"--batch_size\", default=None, type=int, help=\"Batch size.\")\nparser.add_argument(\"--epochs\", default=None, type=int, help=\"Number of epochs.\")\nparser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\nparser.add_argument(\"--threads\", default=1, type=int, help=\"Maximum number of threads to use.\")\nparser.add_argument(\"--buffer_size\", default=None, type=int, help=\"Dataset buffer size to load into memory. By default load the whole dataset.\")\nparser.add_argument(\"--checkpoints_period\", default=None, type=int, help=\"Checkpoint callback period.\")\nparser.add_argument(\"--stopping_patience\", default=None, type=int, help=\"Early stopping epochs patience.\")\nparser.add_argument(\"--label_smoothing\", default=None, type=float, help=\"\")\nparser.add_argument(\"--densenet_filters\", default=32, type=int, help=\"\")\nparser.add_argument(\"--densenet_block_sizes\", nargs=\"+\", type=int, default=[6, 12, 24, 16], help=\"Individual dense block sizes\")\nparser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Initial model learning rate.\")\n\nargs = parser.parse_args([\n    '--threads=4',\n    '--batch_size=4',\n    '--epochs=10',\n    '--checkpoints_period=3',\n    '--stopping_patience=3',\n    '--learning_rate=0.01',\n    #'--label_smoothing=0.1',\n    '--densenet_filters=32',\n    '--buffer_size=128',\n    '--densenet_block_sizes', '8', '10', #'10', #'8',\n] if \"__file__\" not in globals() else None)\n\n# Create logdir name\nargs.logdir = os.path.join(\n    \"logs\",\n    \"{}-{}-{}\".format(\n        os.path.basename(globals().get(\"__file__\", \"notebook\")),\n        datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"),\n        \",\".join(\n            (\n                \"{}={}\".format(re.sub(\"(.)[^_]*_?\", r\"\\1\", k), v)\n                for k, v in sorted(vars(args).items())\n            )\n        ),\n    ),\n)\n\ntf.random.set_seed(args.seed) # tf2.6 (I have gpu issues on tf2.8 unfortunately)\ntf.config.threading.set_inter_op_parallelism_threads(args.threads)\ntf.config.threading.set_intra_op_parallelism_threads(args.threads)\n\nargs","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:45:09.965451Z","iopub.execute_input":"2022-05-12T05:45:09.966070Z","iopub.status.idle":"2022-05-12T05:45:09.990721Z","shell.execute_reply.started":"2022-05-12T05:45:09.966030Z","shell.execute_reply":"2022-05-12T05:45:09.989883Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"args.decay_steps = int(args.epochs * len(homr.train) / args.batch_size)\nif args.buffer_size is None:\n    args.buffer_size = len(homr.train)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T16:16:51.565062Z","iopub.execute_input":"2022-05-11T16:16:51.565380Z","iopub.status.idle":"2022-05-11T16:16:51.571449Z","shell.execute_reply.started":"2022-05-11T16:16:51.565343Z","shell.execute_reply":"2022-05-11T16:16:51.570667Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data","metadata":{}},{"cell_type":"code","source":"homr = HOMRDataset()\n\nif args.buffer_size is None:\n    args.buffer_size = len(homr.train)\n    \nargs.decay_steps = int(args.epochs * len(homr.train) / args.batch_size)\nNULL_CHAR = len(homr.MARKS)\nprint(\"First 10 classes: \", homr.MARKS[:10], '...')\nprint(\"Total num of classes: \", len(homr.MARKS))\nprint(\"Total train dataset cardinality: \", homr.train.cardinality())\nprint(\"Total dev dataset cardinality: \", homr.dev.cardinality())","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:45:23.258549Z","iopub.execute_input":"2022-05-12T05:45:23.258812Z","iopub.status.idle":"2022-05-12T05:45:26.154300Z","shell.execute_reply.started":"2022-05-12T05:45:23.258777Z","shell.execute_reply":"2022-05-12T05:45:26.153614Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for x in homr.train.take(10).as_numpy_iterator():\n    print(x['image'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T14:22:02.531671Z","iopub.execute_input":"2022-05-11T14:22:02.532209Z","iopub.status.idle":"2022-05-11T14:22:02.568105Z","shell.execute_reply.started":"2022-05-11T14:22:02.532165Z","shell.execute_reply":"2022-05-11T14:22:02.567415Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for x in homr.train.take(10).as_numpy_iterator():\n    print(x['marks'].shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T14:22:04.856313Z","iopub.execute_input":"2022-05-11T14:22:04.856948Z","iopub.status.idle":"2022-05-11T14:22:04.892423Z","shell.execute_reply.started":"2022-05-11T14:22:04.856897Z","shell.execute_reply":"2022-05-11T14:22:04.891702Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"_N = 3000\nheights = list()\nwidths = list()\nlabels = list()\nlabels_len = list()\nfor x in homr.train.take(_N).as_numpy_iterator():\n    heights.append(x['image'].shape[0])\n    widths.append(x['image'].shape[1])\n    labels.extend(x['marks'])\n    labels_len.append(x['marks'].shape[0])\n    \nheights = np.array(heights)\nwidths = np.array(widths)\nlabels = np.array(labels)\nlabels_len = np.array(labels_len)\n\nprint(np.mean(heights), np.std(heights), 3 * np.std(heights))\nprint(np.mean(widths), np.std(widths), 3 * np.std(widths))\n\nTARGET_HEIGHT = int(np.ceil(np.mean(heights) + 3 * np.std(heights)))\nTARGET_WIDTH = int(np.ceil(np.mean(widths) + 3 * np.std(widths)))\nTARGET_LABEL_LEN = int(np.ceil(np.mean(labels_len) + 3 * np.std(labels_len)))\n\nprint(\"Target height: \", TARGET_HEIGHT)\nprint(\"Target width: \", TARGET_WIDTH)\nprint(\"Target label_len: \", TARGET_LABEL_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:45:33.031303Z","iopub.execute_input":"2022-05-12T05:45:33.031949Z","iopub.status.idle":"2022-05-12T05:45:35.927931Z","shell.execute_reply.started":"2022-05-12T05:45:33.031912Z","shell.execute_reply":"2022-05-12T05:45:35.927276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.histplot(heights, kde=True, discrete=True).set_title(\"Train images heights distribution of the first {} samples\".format(_N))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T14:22:08.036264Z","iopub.execute_input":"2022-05-11T14:22:08.036666Z","iopub.status.idle":"2022-05-11T14:22:08.526390Z","shell.execute_reply.started":"2022-05-11T14:22:08.036630Z","shell.execute_reply":"2022-05-11T14:22:08.525650Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.histplot(widths, kde=True, discrete=True).set_title(\"Train images widths distribution of the first {} samples\".format(_N))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T14:22:11.004645Z","iopub.execute_input":"2022-05-11T14:22:11.005492Z","iopub.status.idle":"2022-05-11T14:22:13.741991Z","shell.execute_reply.started":"2022-05-11T14:22:11.005443Z","shell.execute_reply":"2022-05-11T14:22:13.741231Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,7))\nsns.histplot(labels, kde=True, discrete=True).set_title(\"Train marks distribution of the first {} samples\".format(_N))","metadata":{"execution":{"iopub.status.busy":"2022-05-11T14:22:16.948974Z","iopub.execute_input":"2022-05-11T14:22:16.949716Z","iopub.status.idle":"2022-05-11T14:22:19.164707Z","shell.execute_reply.started":"2022-05-11T14:22:16.949676Z","shell.execute_reply":"2022-05-11T14:22:19.163978Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"del labels, heights","metadata":{"execution":{"iopub.status.busy":"2022-05-11T12:23:17.381071Z","iopub.execute_input":"2022-05-11T12:23:17.38133Z","iopub.status.idle":"2022-05-11T12:23:17.387538Z","shell.execute_reply.started":"2022-05-11T12:23:17.381301Z","shell.execute_reply":"2022-05-11T12:23:17.386828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(name):\n    def prepare_example(example):\n        label = tf.cast(example[\"marks\"] if args.label_smoothing is None else tf.one_hot(example[\"labels\"], len(modelnet.LABELS)), tf.int32)\n        image = tf.cast(example[\"image\"], tf.float32)\n        #image = tf.image.resize_with_crop_or_pad(image, TARGET_HEIGHT, TARGET_WIDTH)\n        image = tf.image.resize_with_crop_or_pad(image, TARGET_HEIGHT, tf.shape(image)[1])\n        return (image, label)\n\n    dataset = getattr(homr, name).map(prepare_example)\n    #dataset = dataset.shuffle(len(dataset), seed=args.seed) if name == \"train\" else dataset\n    dataset = dataset.shuffle(args.buffer_size, seed=args.seed) if name == \"train\" else dataset\n    dataset = dataset.apply(tf.data.experimental.dense_to_ragged_batch(args.batch_size))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset\n\ntrain, dev, test = create_dataset(\"train\"), create_dataset(\"dev\"), create_dataset(\"test\")\nprint(train, '\\n', dev, '\\n', test)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:45:56.268595Z","iopub.execute_input":"2022-05-12T05:45:56.268855Z","iopub.status.idle":"2022-05-12T05:45:56.732595Z","shell.execute_reply.started":"2022-05-12T05:45:56.268820Z","shell.execute_reply":"2022-05-12T05:45:56.731871Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"code","source":"class Model(tf.keras.Model):\n    \n    class DenseBlockPart(tf.keras.layers.Layer):\n        def __init__(self, filters, kernel, strides, padding = \"same\", activation: str = \"relu\", *args, **kwargs) -> None:\n            super().__init__(*args, **kwargs)\n            \n            self.activation, self.filters, self.kernel, self.strides, self.padding = (\n                activation, filters, kernel, strides, padding\n            )\n            \n            self.layers = {\n                \"batchnorm\": tf.keras.layers.BatchNormalization(),\n                \"activation\": tf.keras.layers.Activation(self.activation),\n                \"conv\": tf.keras.layers.Conv2D(self.filters, self.kernel, self.strides, self.padding)\n            }\n            \n            \n        def get_config(self):\n            return {\n                \"activation\": self.activation,\n                \"filters\": self.filters,\n                \"kernel\": self.kernel,\n                \"strides\": self.strides,\n                \"padding\": self.padding\n            }\n        \n        def call(self, inputs, mask=None):\n            x = self.layers[\"batchnorm\"](inputs)\n            x = self.layers[\"activation\"](x)\n            x = self.layers[\"conv\"](x)\n            return x\n\n    class DenseBlock(tf.keras.layers.Layer):\n        def __init__(self, size, filters, *args, **kwargs) -> None:\n            super().__init__(*args, **kwargs)\n            \n            self.size, self.filters = size, filters\n            \n            self.layers = list()\n            for _ in range(self.size):\n                self.layers.append({\n                    \"1x1_part\": Model.DenseBlockPart(4 * self.filters, 1, 1, \"same\", \"relu\"),\n                    \"3x3_part\": Model.DenseBlockPart(self.filters, 3, 1, \"same\", \"relu\")\n                })\n\n        def get_config(self):\n            return {\n                \"size\": self.size,\n                \"filters\": self.filters\n            }\n        \n        def call(self, inputs, mask=None):\n            x = inputs\n            for layer in self.layers:\n                y = layer[\"1x1_part\"](x)\n                y = layer[\"3x3_part\"](y)\n                x = tf.keras.layers.Concatenate()([y, x])\n            return x\n        \n    class TransitionLayer(tf.keras.layers.Layer):\n        def __init__(self, filters, *args, **kwargs) -> None:\n            super().__init__(*args, **kwargs)\n            self.filters = filters\n            \n            self.layers = {\n                \"denseblock_part\": Model.DenseBlockPart(filters, 1, 1, \"same\", \"relu\"),\n                \"pooling\": tf.keras.layers.MaxPool2D(2, 2, padding=\"same\")\n            }\n            \n        def get_config(self):\n            return {\n                \"filters\": self.filters\n            }\n        \n        def call(self, inputs, mask=None):\n            hidden = self.layers[\"denseblock_part\"](inputs)\n            hidden = self.layers[\"pooling\"](hidden)\n            return hidden\n        \n    class DenseNet(tf.keras.layers.Layer):\n        def __init__(self, filters, block_sizes, *args, **kwargs) -> None:\n            super().__init__(*args, **kwargs)\n            self.filters, self.block_sizes = filters, block_sizes\n            self.layers = {\n                \"init_conv\": tf.keras.layers.Conv2D(64, 7, 2, \"same\"),\n                \"init_pool\": tf.keras.layers.MaxPool2D(3, 2),\n                \"body\": list()\n            }\n            \n            for block_size in self.block_sizes:\n                self.layers[\"body\"].append({\n                    \"denseblock\": Model.DenseBlock(self.filters, block_size),\n                    \"transition\": Model.TransitionLayer(self.filters // 2)\n                })\n            \n        def get_config(self):\n            return {\n                \"filters\": self.filters,\n                \"block_sizes\": self.block_sizes\n            }\n        \n        def call(self, inputs, mask=None):\n            x = self.layers[\"init_conv\"](inputs)\n            x = self.layers[\"init_pool\"](x)\n            \n            for layer in self.layers[\"body\"]:\n                x = layer[\"denseblock\"](x)\n                x = layer[\"transition\"](x)\n            return x\n    \n    \n    def __init__(self, args: argparse.Namespace) -> None:\n        inputs = tf.keras.layers.Input(shape=[TARGET_HEIGHT, None, 1], dtype=tf.float32, ragged=True)\n        \n        hidden = self.DenseNet(args.densenet_filters, args.densenet_block_sizes)(inputs.to_tensor())\n        \n        hidden = tf.keras.layers.Reshape([-1, hidden.shape[-1] * hidden.shape[1]])(hidden)\n        hidden = tf.RaggedTensor.from_tensor(hidden)\n        \n        hidden = tf.keras.layers.Bidirectional(\n            tf.keras.layers.RNN(tfa.rnn.LayerNormLSTMCell(32, recurrent_dropout=0.2, dropout=0.05),return_sequences=True, return_state=False),\n            merge_mode=\"sum\"\n        )(hidden)\n        \n        hidden = tf.keras.layers.RNN(tfa.rnn.LayerNormLSTMCell(32, recurrent_dropout=0.2, dropout=0.05), return_sequences=True, return_state=False)(hidden)\n        hidden = tf.keras.layers.RNN(tfa.rnn.LayerNormLSTMCell(32, recurrent_dropout=0.2, dropout=0.05), return_sequences=True, return_state=False)(hidden)\n           \n        logits = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1 + len(homr.MARKS), activation=None))(hidden)\n        \n        super().__init__(inputs=inputs, outputs=logits)\n\n        self.compile(optimizer=tf.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.CosineDecay(args.learning_rate, args.decay_steps)),\n                     loss=self.ctc_loss,\n                     metrics=[homr.EditDistanceMetric()])\n\n        self.callbacks = list()\n        self.tb_callback = tf.keras.callbacks.TensorBoard(args.logdir)\n        self.callbacks.append(self.tb_callback)\n        if args.checkpoints_period:\n            self.checkpoints = tf.keras.callbacks.ModelCheckpoint('weights{epoch:08d}.h5', save_weights_only=True, period=args.checkpoints_period) \n            self.callbacks.append(self.checkpoints)\n        if args.stopping_patience:\n            self.early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=args.stopping_patience)\n            self.callbacks.append(self.early_stopping)\n\n    def ctc_loss(self, gold_labels: tf.RaggedTensor, logits: tf.RaggedTensor) -> tf.Tensor:\n        assert isinstance(gold_labels, tf.RaggedTensor), \"Gold labels given to CTC loss must be RaggedTensors\"\n        assert isinstance(logits, tf.RaggedTensor), \"Logits given to CTC loss must be RaggedTensors\"\n\n        return tf.reduce_mean( \n            tf.nn.ctc_loss( \n                gold_labels.to_sparse(),\n                tf.transpose(logits.to_tensor(), perm=[1, 0, 2]),\n                label_length=None,\n                logit_length=tf.cast(logits.row_lengths(), tf.int32),\n                #logits_time_major=False,\n                blank_index=-1 # TODO, check?\n            ),\n            axis=0\n        )\n\n    def ctc_decode(self, logits: tf.RaggedTensor) -> tf.RaggedTensor:\n        assert isinstance(logits, tf.RaggedTensor), \"Logits given to CTC predict must be RaggedTensors\"\n\n        predictions, _ = tf.nn.ctc_beam_search_decoder(\n            tf.transpose(logits.to_tensor(), perm=[1, 0, 2]),\n            tf.cast(logits.row_lengths(), tf.int32),\n        )\n        predictions = tf.RaggedTensor.from_sparse(predictions[0])\n\n        assert isinstance(predictions, tf.RaggedTensor), \"CTC predictions must be RaggedTensors\"\n        return predictions\n\n    def train_step(self, data):\n        x, y = data\n        with tf.GradientTape() as tape:\n            y_pred = self(x, training=True)\n            loss = self.compute_loss(x, y, y_pred) # TF2.6. COMPATIBILITY\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n        return {\"loss\": metric.result() for metric in self.metrics if metric.name == \"loss\"}\n\n    def predict_step(self, data):\n        data = data[0] if isinstance(data, tuple) else data\n        y_pred = self(data, training=False)\n        y_pred = self.ctc_decode(y_pred)\n        return y_pred\n\n    def test_step(self, data):\n        x, y = data\n        y_pred = self(x, training=False)\n        self.compute_loss(x, y, y_pred)\n        y_pred = self.ctc_decode(y_pred)\n        return self.compute_metrics(x, y, y_pred, None)\n    \n    def compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None):\n        del x  # The default implementation does not use `x`.\n        return self.compiled_loss(\n            y, y_pred, sample_weight, regularization_losses=self.losses)\n    \n    def compute_metrics(self, x, y, y_pred, sample_weight):\n        del x  # The default implementation does not use `x`.\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n        # Collect metrics to return\n        return_metrics = {}\n        for metric in self.metrics:\n            result = metric.result()\n            if isinstance(result, dict):\n                return_metrics.update(result)\n            else:\n                return_metrics[metric.name] = result\n        return return_metrics\n    \nmodel = Model(args)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:48:46.889759Z","iopub.execute_input":"2022-05-12T05:48:46.890040Z","iopub.status.idle":"2022-05-12T05:48:50.271825Z","shell.execute_reply.started":"2022-05-12T05:48:46.890007Z","shell.execute_reply":"2022-05-12T05:48:50.271046Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"logs = model.fit(\n    train, \n    epochs=args.epochs,\n    validation_data=dev,\n    shuffle=False,\n    callbacks=[model.callbacks],\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T05:48:54.114875Z","iopub.execute_input":"2022-05-12T05:48:54.115359Z","iopub.status.idle":"2022-05-12T06:15:14.083389Z","shell.execute_reply.started":"2022-05-12T05:48:54.115322Z","shell.execute_reply":"2022-05-12T06:15:14.082192Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"del model, train, dev, test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-05-04T14:49:43.533526Z","iopub.execute_input":"2022-05-04T14:49:43.533869Z","iopub.status.idle":"2022-05-04T14:49:43.899475Z","shell.execute_reply.started":"2022-05-04T14:49:43.533837Z","shell.execute_reply":"2022-05-04T14:49:43.898887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils.vis_utils import plot_model\nplot_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Predictions","metadata":{}},{"cell_type":"code","source":"os.makedirs(args.logdir, exist_ok=True)\nwith open(os.path.join(args.logdir, \"homr_competition.txt\"), \"w\", encoding=\"utf-8\") as predictions_file:\n    # TODO: Predict the sequences of recognized marks.\n    predictions = model.predict(test)\n\n    for sequence in predictions:\n        print(\" \".join(homr.MARKS[mark] for mark in sequence), file=predictions_file)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T06:15:20.329277Z","iopub.execute_input":"2022-05-12T06:15:20.329533Z","iopub.status.idle":"2022-05-12T09:33:34.558783Z","shell.execute_reply.started":"2022-05-12T06:15:20.329503Z","shell.execute_reply":"2022-05-12T09:33:34.558023Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"args.logdir","metadata":{},"execution_count":null,"outputs":[]}]}