{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The goal of this assignment is to devise the best possible model for CIFAR-10. You can load the data using the cifar10.py module. Note that the test set is different than that of official CIFAR-10.\n\nThe task is a competition. Everyone who submits a solution which achieves at least 65% test set accuracy will get 5 points; the rest 5 points will be distributed depending on relative ordering of your solutions. Note that my solutions usually need to achieve around ~80% on the development set to score 65% on the test set.\n\nYou may want to start with the cifar_competition.py template which generates the test set annotation in the required format.","metadata":{}},{"cell_type":"code","source":"#!/usr/bin/env python3\n# 53907afe-531b-11ea-a595-00505601122b\n# b7ea974c-d389-11e8-a4be-00505601122b","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:57:20.397258Z","iopub.execute_input":"2022-03-23T13:57:20.397793Z","iopub.status.idle":"2022-03-23T13:57:20.418586Z","shell.execute_reply.started":"2022-03-23T13:57:20.397698Z","shell.execute_reply":"2022-03-23T13:57:20.417916Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!cp /kaggle/input/cifar10/cifar10.py /kaggle/working/cifar10.py\n!cp /kaggle/input/cifar10-data/cifar10_competition.npz /kaggle/working/cifar10_competition.npz","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:57:20.992407Z","iopub.execute_input":"2022-03-23T13:57:20.992685Z","iopub.status.idle":"2022-03-23T13:57:24.973435Z","shell.execute_reply.started":"2022-03-23T13:57:20.992654Z","shell.execute_reply":"2022-03-23T13:57:24.972286Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#!pip install -U tensorflow==2.8 tensorflow-addons==0.16.1 tensorflow-probability==0.16.0 tensorflow-hub==0.12.0 scipy\n!pip freeze | grep tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:57:27.297430Z","iopub.execute_input":"2022-03-23T13:57:27.297723Z","iopub.status.idle":"2022-03-23T13:57:30.650096Z","shell.execute_reply.started":"2022-03-23T13:57:27.297692Z","shell.execute_reply":"2022-03-23T13:57:30.649248Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"tensorflow @ file:///opt/conda/conda-bld/dlenv-tf-2-6-gpu_1639878970787/work/tensorflow-2.6.2-cp37-cp37m-linux_x86_64.whl\ntensorflow-addons==0.14.0\ntensorflow-cloud==0.1.14\ntensorflow-datasets==4.3.0\ntensorflow-estimator==2.6.0\ntensorflow-gcs-config==2.6.0\ntensorflow-hub==0.12.0\ntensorflow-io==0.21.0\ntensorflow-metadata==1.5.0\ntensorflow-probability==0.14.1\ntensorflow-serving-api==2.7.0\ntensorflow-transform==1.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import argparse\nimport datetime\nimport os\nimport re\n\nos.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # Report only TF errors by default\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom cifar10 import CIFAR10","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:57:33.184481Z","iopub.execute_input":"2022-03-23T13:57:33.185148Z","iopub.status.idle":"2022-03-23T13:57:37.380560Z","shell.execute_reply.started":"2022-03-23T13:57:33.185096Z","shell.execute_reply":"2022-03-23T13:57:37.379825Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument(\"--batch_size\", default=None, type=int, help=\"Batch size.\")\nparser.add_argument(\"--epochs\", default=None, type=int, help=\"Number of epochs.\")\nparser.add_argument(\"--seed\", default=42, type=int, help=\"Random seed.\")\nparser.add_argument(\"--threads\", default=1, type=int, help=\"Maximum number of threads to use.\")\nparser.add_argument(\"--checkpoints_period\", default=None, type=int, help=\"Checkpoint callback period.\")\nparser.add_argument(\"--stopping_patience\", default=None, type=int, help=\"Early stopping epochs patience.\")\nparser.add_argument(\"--densenet_filters\", default=32, type=int, help=\"\")\nparser.add_argument(\"--densenet_block_sizes\", nargs=\"+\", type=int, default=[6, 12, 24, 16], help=\"Individual dense block sizes\") # default being DenseNet-121\nparser.add_argument(\"--label_smoothing\", default=None, type=float, help=\"\")\nparser.add_argument(\"--learning_rate\", default=0.01, type=float, help=\"Initial model learning rate.\")\n\nargs = parser.parse_args([\n    '--batch_size=128',\n    '--epochs=50',\n    '--checkpoints_period=3',\n    '--stopping_patience=3',\n    '--densenet_filters=32',\n    '--densenet_block_sizes', '3', '6', '10', '8',\n    '--label_smoothing=0.1'\n] if \"__file__\" not in globals() else None)\n\n# Create logdir name\nargs.logdir = os.path.join(\n    \"logs\",\n    \"{}-{}-{}\".format(\n        os.path.basename(globals().get(\"__file__\", \"notebook\")),\n        datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\"),\n        \",\".join(\n            (\n                \"{}={}\".format(re.sub(\"(.)[^_]*_?\", r\"\\1\", k), v)\n                for k, v in sorted(vars(args).items())\n            )\n        ),\n    ),\n)\n\n#tf.keras.utils.set_random_seed(args.seed)\ntf.random.set_seed(args.seed) # tf2.6 (I have gpu issues on tf2.8 unfortunately)\ntf.config.threading.set_inter_op_parallelism_threads(args.threads)\ntf.config.threading.set_intra_op_parallelism_threads(args.threads)\n\nargs","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:57:39.650898Z","iopub.execute_input":"2022-03-23T13:57:39.651179Z","iopub.status.idle":"2022-03-23T13:57:39.676566Z","shell.execute_reply.started":"2022-03-23T13:57:39.651148Z","shell.execute_reply":"2022-03-23T13:57:39.675679Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Namespace(batch_size=128, checkpoints_period=3, densenet_block_sizes=[3, 6, 10, 8], densenet_filters=32, epochs=50, label_smoothing=0.1, learning_rate=0.01, logdir='logs/notebook-2022-03-23_135739-bs=128,cp=3,dbs=[3, 6, 10, 8],df=32,e=50,ls=0.1,lr=0.01,s=42,sp=3,t=1', seed=42, stopping_patience=3, threads=1)"},"metadata":{}}]},{"cell_type":"code","source":"cifar = CIFAR10()\n\nif args.label_smoothing:\n    cifar.train.data['labels'] = tf.keras.utils.to_categorical(\n        cifar.train.data['labels'],\n        num_classes=cifar.LABELS\n    )\n    cifar.dev.data['labels'] = tf.keras.utils.to_categorical(\n        cifar.dev.data['labels'],\n        num_classes=cifar.LABELS\n    )\n    \nargs.decay_steps = int(args.epochs * cifar.train.size / args.batch_size)\n    \nprint(cifar.train.data['images'].shape, cifar.train.data['labels'].shape)\nprint(CIFAR10.LABELS, CIFAR10.LABEL_NAMES)\nprint(CIFAR10.H, CIFAR10.W, CIFAR10.C)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:57:45.164950Z","iopub.execute_input":"2022-03-23T13:57:45.165208Z","iopub.status.idle":"2022-03-23T13:57:47.289394Z","shell.execute_reply.started":"2022-03-23T13:57:45.165177Z","shell.execute_reply":"2022-03-23T13:57:47.288539Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(45000, 32, 32, 3) (45000, 10)\n10 ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n32 32 3\n","output_type":"stream"}]},{"cell_type":"code","source":"# Helper function to create denseblocks\n# instead of doing Conv -> BN -> Activ we do\n# BN -> Activ -> Conv so we can easily\n# return Conv layer and concatenate it into\n# the dense block\ndef _dense_block_part(hidden, filters, kernel, activation=\"relu\"):\n    hidden = tf.keras.layers.BatchNormalization()(hidden)\n    hidden = tf.keras.layers.Activation(activation)(hidden)\n    return tf.keras.layers.Conv2D(filters, kernel, 1, padding=\"same\")(hidden)\n\ndef dense_block(hidden, filters, dense_block_size):\n    for _ in range(dense_block_size):\n        hidden_part = _dense_block_part(hidden, 4 * filters, 1) # 1x1 kernel conv layer\n        hidden_part = _dense_block_part(hidden_part, filters, 3) # 3x3 kernel conv layer\n        hidden = tf.keras.layers.Concatenate()([hidden_part, hidden]) # append output to residualy connected hidden inputs\n    return hidden\n\ndef transition_layer(hidden):\n    hidden = _dense_block_part(hidden, hidden.shape[-1] // 2, 1)\n    return tf.keras.layers.MaxPool2D(2, 2, padding=\"same\")(hidden)\n    \n\n# Architecture inspired from DenseNet121 (https://arxiv.org/pdf/1608.06993.pdf)\n# mostly just reduced parameters and other specifics\n# \n# Idea of _dense_block_part doing BN -> Activ -> Conv instead of Conv -> BN -> Activ\n# is taken from https://towardsdatascience.com/creating-densenet-121-with-tensorflow-edbc08a956d8\ndef build_denselike_net(filters, dense_block_sizes):    \n    inputs = tf.keras.layers.Input(shape=[CIFAR10.H, CIFAR10.W, CIFAR10.C])\n    hidden = tf.keras.layers.Conv2D(64, 7, 2, \"same\")(inputs)\n    hidden = tf.keras.layers.MaxPooling2D(3, 2)(hidden)\n    \n    for dense_block_size in dense_block_sizes:\n        hidden_part = dense_block(hidden, filters, dense_block_size)\n        hidden = transition_layer(hidden_part)\n    \n    hidden = tf.keras.layers.GlobalAveragePooling2D()(hidden_part)\n    #hidden = tf.keras.layers.Flatten()(hidden)\n    #hidden = tf.keras.layers.Dense(128)(hidden)\n    #hidden = tf.keras.layers.BatchNormalization()(hidden)\n    #hidden = tf.keras.layers.Activation('relu')(hidden)\n    outputs = tf.keras.layers.Dense(CIFAR10.LABELS, activation=\"softmax\")(hidden)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model\n\nmodel = build_denselike_net(args.densenet_filters, args.densenet_block_sizes)\n\nif args.label_smoothing:\n    loss = tf.losses.CategoricalCrossentropy(label_smoothing=args.label_smoothing)\n    metrics = [tf.metrics.CategoricalAccuracy(name=\"accuracy\")]\nelse:\n    loss = tf.losses.SparseCategoricalCrossentropy(label_smoothing=args.label_smoothing)\n    metrics = [tf.metrics.SparseCategoricalAccuracy(name=\"accuracy\")]\n\nmodel.compile(\n    optimizer=tf.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.CosineDecay(args.learning_rate, args.decay_steps)),\n    loss=loss,\n    metrics=metrics,\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:58:08.389599Z","iopub.execute_input":"2022-03-23T13:58:08.390300Z","iopub.status.idle":"2022-03-23T13:58:11.952014Z","shell.execute_reply.started":"2022-03-23T13:58:08.390259Z","shell.execute_reply":"2022-03-23T13:58:11.951304Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 16, 16, 64)   9472        input_1[0][0]                    \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 7, 7, 64)     0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 7, 7, 64)     256         max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 7, 7, 64)     0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 7, 7, 128)    8320        activation[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 7, 7, 128)    512         conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 7, 7, 128)    0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 7, 7, 32)     36896       activation_1[0][0]               \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 7, 7, 96)     0           conv2d_2[0][0]                   \n                                                                 max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 7, 7, 96)     384         concatenate[0][0]                \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 7, 7, 96)     0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 7, 7, 128)    12416       activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 7, 7, 128)    512         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 7, 7, 128)    0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 7, 7, 32)     36896       activation_3[0][0]               \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 7, 7, 128)    0           conv2d_4[0][0]                   \n                                                                 concatenate[0][0]                \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 7, 7, 128)    512         concatenate_1[0][0]              \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 7, 7, 128)    0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 7, 7, 128)    16512       activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 7, 7, 128)    512         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 7, 7, 128)    0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 7, 7, 32)     36896       activation_5[0][0]               \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 7, 7, 160)    0           conv2d_6[0][0]                   \n                                                                 concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 7, 7, 160)    640         concatenate_2[0][0]              \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 7, 7, 160)    0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 7, 7, 80)     12880       activation_6[0][0]               \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 4, 4, 80)     0           conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 4, 4, 80)     320         max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 4, 4, 80)     0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 4, 4, 128)    10368       activation_7[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_8 (BatchNor (None, 4, 4, 128)    512         conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 4, 4, 128)    0           batch_normalization_8[0][0]      \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 4, 4, 32)     36896       activation_8[0][0]               \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 4, 4, 112)    0           conv2d_9[0][0]                   \n                                                                 max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_9 (BatchNor (None, 4, 4, 112)    448         concatenate_3[0][0]              \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 4, 4, 112)    0           batch_normalization_9[0][0]      \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 4, 4, 128)    14464       activation_9[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_10 (BatchNo (None, 4, 4, 128)    512         conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 4, 4, 128)    0           batch_normalization_10[0][0]     \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 4, 4, 32)     36896       activation_10[0][0]              \n__________________________________________________________________________________________________\nconcatenate_4 (Concatenate)     (None, 4, 4, 144)    0           conv2d_11[0][0]                  \n                                                                 concatenate_3[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_11 (BatchNo (None, 4, 4, 144)    576         concatenate_4[0][0]              \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 4, 4, 144)    0           batch_normalization_11[0][0]     \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 4, 4, 128)    18560       activation_11[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 4, 4, 128)    0           batch_normalization_12[0][0]     \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 4, 4, 32)     36896       activation_12[0][0]              \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 4, 4, 176)    0           conv2d_13[0][0]                  \n                                                                 concatenate_4[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_13 (BatchNo (None, 4, 4, 176)    704         concatenate_5[0][0]              \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 4, 4, 176)    0           batch_normalization_13[0][0]     \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 4, 4, 128)    22656       activation_13[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_14 (BatchNo (None, 4, 4, 128)    512         conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 4, 4, 32)     36896       activation_14[0][0]              \n__________________________________________________________________________________________________\nconcatenate_6 (Concatenate)     (None, 4, 4, 208)    0           conv2d_15[0][0]                  \n                                                                 concatenate_5[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_15 (BatchNo (None, 4, 4, 208)    832         concatenate_6[0][0]              \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 4, 4, 208)    0           batch_normalization_15[0][0]     \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 4, 4, 128)    26752       activation_15[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_16 (BatchNo (None, 4, 4, 128)    512         conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 4, 4, 128)    0           batch_normalization_16[0][0]     \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 4, 4, 32)     36896       activation_16[0][0]              \n__________________________________________________________________________________________________\nconcatenate_7 (Concatenate)     (None, 4, 4, 240)    0           conv2d_17[0][0]                  \n                                                                 concatenate_6[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_17 (BatchNo (None, 4, 4, 240)    960         concatenate_7[0][0]              \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 4, 4, 240)    0           batch_normalization_17[0][0]     \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 4, 4, 128)    30848       activation_17[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_18 (BatchNo (None, 4, 4, 128)    512         conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 4, 4, 128)    0           batch_normalization_18[0][0]     \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 4, 4, 32)     36896       activation_18[0][0]              \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 4, 4, 272)    0           conv2d_19[0][0]                  \n                                                                 concatenate_7[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_19 (BatchNo (None, 4, 4, 272)    1088        concatenate_8[0][0]              \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 4, 4, 272)    0           batch_normalization_19[0][0]     \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 4, 4, 136)    37128       activation_19[0][0]              \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 2, 2, 136)    0           conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_20 (BatchNo (None, 2, 2, 136)    544         max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 2, 2, 136)    0           batch_normalization_20[0][0]     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 2, 2, 128)    17536       activation_20[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_21 (BatchNo (None, 2, 2, 128)    512         conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 2, 2, 128)    0           batch_normalization_21[0][0]     \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 2, 2, 32)     36896       activation_21[0][0]              \n__________________________________________________________________________________________________\nconcatenate_9 (Concatenate)     (None, 2, 2, 168)    0           conv2d_22[0][0]                  \n                                                                 max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_22 (BatchNo (None, 2, 2, 168)    672         concatenate_9[0][0]              \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 2, 2, 168)    0           batch_normalization_22[0][0]     \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 2, 2, 128)    21632       activation_22[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_23 (BatchNo (None, 2, 2, 128)    512         conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 2, 2, 128)    0           batch_normalization_23[0][0]     \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 2, 2, 32)     36896       activation_23[0][0]              \n__________________________________________________________________________________________________\nconcatenate_10 (Concatenate)    (None, 2, 2, 200)    0           conv2d_24[0][0]                  \n                                                                 concatenate_9[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_24 (BatchNo (None, 2, 2, 200)    800         concatenate_10[0][0]             \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 2, 2, 200)    0           batch_normalization_24[0][0]     \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 2, 2, 128)    25728       activation_24[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_25 (BatchNo (None, 2, 2, 128)    512         conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 2, 2, 128)    0           batch_normalization_25[0][0]     \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 2, 2, 32)     36896       activation_25[0][0]              \n__________________________________________________________________________________________________\nconcatenate_11 (Concatenate)    (None, 2, 2, 232)    0           conv2d_26[0][0]                  \n                                                                 concatenate_10[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_26 (BatchNo (None, 2, 2, 232)    928         concatenate_11[0][0]             \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 2, 2, 232)    0           batch_normalization_26[0][0]     \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 2, 2, 128)    29824       activation_26[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_27 (BatchNo (None, 2, 2, 128)    512         conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 2, 2, 128)    0           batch_normalization_27[0][0]     \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 2, 2, 32)     36896       activation_27[0][0]              \n__________________________________________________________________________________________________\nconcatenate_12 (Concatenate)    (None, 2, 2, 264)    0           conv2d_28[0][0]                  \n                                                                 concatenate_11[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_28 (BatchNo (None, 2, 2, 264)    1056        concatenate_12[0][0]             \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 2, 2, 264)    0           batch_normalization_28[0][0]     \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 2, 2, 128)    33920       activation_28[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_29 (BatchNo (None, 2, 2, 128)    512         conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 2, 2, 128)    0           batch_normalization_29[0][0]     \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 2, 2, 32)     36896       activation_29[0][0]              \n__________________________________________________________________________________________________\nconcatenate_13 (Concatenate)    (None, 2, 2, 296)    0           conv2d_30[0][0]                  \n                                                                 concatenate_12[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_30 (BatchNo (None, 2, 2, 296)    1184        concatenate_13[0][0]             \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 2, 2, 296)    0           batch_normalization_30[0][0]     \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 2, 2, 128)    38016       activation_30[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_31 (BatchNo (None, 2, 2, 128)    512         conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 2, 2, 128)    0           batch_normalization_31[0][0]     \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 2, 2, 32)     36896       activation_31[0][0]              \n__________________________________________________________________________________________________\nconcatenate_14 (Concatenate)    (None, 2, 2, 328)    0           conv2d_32[0][0]                  \n                                                                 concatenate_13[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_32 (BatchNo (None, 2, 2, 328)    1312        concatenate_14[0][0]             \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 2, 2, 328)    0           batch_normalization_32[0][0]     \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 2, 2, 128)    42112       activation_32[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_33 (BatchNo (None, 2, 2, 128)    512         conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 2, 2, 128)    0           batch_normalization_33[0][0]     \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 2, 2, 32)     36896       activation_33[0][0]              \n__________________________________________________________________________________________________\nconcatenate_15 (Concatenate)    (None, 2, 2, 360)    0           conv2d_34[0][0]                  \n                                                                 concatenate_14[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_34 (BatchNo (None, 2, 2, 360)    1440        concatenate_15[0][0]             \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 2, 2, 360)    0           batch_normalization_34[0][0]     \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 2, 2, 128)    46208       activation_34[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_35 (BatchNo (None, 2, 2, 128)    512         conv2d_35[0][0]                  \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 2, 2, 128)    0           batch_normalization_35[0][0]     \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 2, 2, 32)     36896       activation_35[0][0]              \n__________________________________________________________________________________________________\nconcatenate_16 (Concatenate)    (None, 2, 2, 392)    0           conv2d_36[0][0]                  \n                                                                 concatenate_15[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_36 (BatchNo (None, 2, 2, 392)    1568        concatenate_16[0][0]             \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 2, 2, 392)    0           batch_normalization_36[0][0]     \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 2, 2, 128)    50304       activation_36[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_37 (BatchNo (None, 2, 2, 128)    512         conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 2, 2, 128)    0           batch_normalization_37[0][0]     \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 2, 2, 32)     36896       activation_37[0][0]              \n__________________________________________________________________________________________________\nconcatenate_17 (Concatenate)    (None, 2, 2, 424)    0           conv2d_38[0][0]                  \n                                                                 concatenate_16[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_38 (BatchNo (None, 2, 2, 424)    1696        concatenate_17[0][0]             \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 2, 2, 424)    0           batch_normalization_38[0][0]     \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 2, 2, 128)    54400       activation_38[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_39 (BatchNo (None, 2, 2, 128)    512         conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 2, 2, 128)    0           batch_normalization_39[0][0]     \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 2, 2, 32)     36896       activation_39[0][0]              \n__________________________________________________________________________________________________\nconcatenate_18 (Concatenate)    (None, 2, 2, 456)    0           conv2d_40[0][0]                  \n                                                                 concatenate_17[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_40 (BatchNo (None, 2, 2, 456)    1824        concatenate_18[0][0]             \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 2, 2, 456)    0           batch_normalization_40[0][0]     \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 2, 2, 228)    104196      activation_40[0][0]              \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 228)    0           conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_41 (BatchNo (None, 1, 1, 228)    912         max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 1, 1, 228)    0           batch_normalization_41[0][0]     \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 1, 1, 128)    29312       activation_41[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_42 (BatchNo (None, 1, 1, 128)    512         conv2d_42[0][0]                  \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 1, 1, 128)    0           batch_normalization_42[0][0]     \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 1, 1, 32)     36896       activation_42[0][0]              \n__________________________________________________________________________________________________\nconcatenate_19 (Concatenate)    (None, 1, 1, 260)    0           conv2d_43[0][0]                  \n                                                                 max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nbatch_normalization_43 (BatchNo (None, 1, 1, 260)    1040        concatenate_19[0][0]             \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 1, 1, 260)    0           batch_normalization_43[0][0]     \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 1, 1, 128)    33408       activation_43[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_44 (BatchNo (None, 1, 1, 128)    512         conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 1, 1, 128)    0           batch_normalization_44[0][0]     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 1, 1, 32)     36896       activation_44[0][0]              \n__________________________________________________________________________________________________\nconcatenate_20 (Concatenate)    (None, 1, 1, 292)    0           conv2d_45[0][0]                  \n                                                                 concatenate_19[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_45 (BatchNo (None, 1, 1, 292)    1168        concatenate_20[0][0]             \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 1, 1, 292)    0           batch_normalization_45[0][0]     \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 1, 1, 128)    37504       activation_45[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_46 (BatchNo (None, 1, 1, 128)    512         conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 1, 1, 128)    0           batch_normalization_46[0][0]     \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 1, 1, 32)     36896       activation_46[0][0]              \n__________________________________________________________________________________________________\nconcatenate_21 (Concatenate)    (None, 1, 1, 324)    0           conv2d_47[0][0]                  \n                                                                 concatenate_20[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_47 (BatchNo (None, 1, 1, 324)    1296        concatenate_21[0][0]             \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 1, 1, 324)    0           batch_normalization_47[0][0]     \n__________________________________________________________________________________________________\nconv2d_48 (Conv2D)              (None, 1, 1, 128)    41600       activation_47[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_48 (BatchNo (None, 1, 1, 128)    512         conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 1, 1, 128)    0           batch_normalization_48[0][0]     \n__________________________________________________________________________________________________\nconv2d_49 (Conv2D)              (None, 1, 1, 32)     36896       activation_48[0][0]              \n__________________________________________________________________________________________________\nconcatenate_22 (Concatenate)    (None, 1, 1, 356)    0           conv2d_49[0][0]                  \n                                                                 concatenate_21[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_49 (BatchNo (None, 1, 1, 356)    1424        concatenate_22[0][0]             \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 1, 1, 356)    0           batch_normalization_49[0][0]     \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 1, 1, 128)    45696       activation_49[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_50 (BatchNo (None, 1, 1, 128)    512         conv2d_50[0][0]                  \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 1, 1, 128)    0           batch_normalization_50[0][0]     \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 1, 1, 32)     36896       activation_50[0][0]              \n__________________________________________________________________________________________________\nconcatenate_23 (Concatenate)    (None, 1, 1, 388)    0           conv2d_51[0][0]                  \n                                                                 concatenate_22[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_51 (BatchNo (None, 1, 1, 388)    1552        concatenate_23[0][0]             \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 1, 1, 388)    0           batch_normalization_51[0][0]     \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 1, 1, 128)    49792       activation_51[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_52 (BatchNo (None, 1, 1, 128)    512         conv2d_52[0][0]                  \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 1, 1, 128)    0           batch_normalization_52[0][0]     \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 1, 1, 32)     36896       activation_52[0][0]              \n__________________________________________________________________________________________________\nconcatenate_24 (Concatenate)    (None, 1, 1, 420)    0           conv2d_53[0][0]                  \n                                                                 concatenate_23[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_53 (BatchNo (None, 1, 1, 420)    1680        concatenate_24[0][0]             \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 1, 1, 420)    0           batch_normalization_53[0][0]     \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 1, 1, 128)    53888       activation_53[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_54 (BatchNo (None, 1, 1, 128)    512         conv2d_54[0][0]                  \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 1, 1, 128)    0           batch_normalization_54[0][0]     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 1, 1, 32)     36896       activation_54[0][0]              \n__________________________________________________________________________________________________\nconcatenate_25 (Concatenate)    (None, 1, 1, 452)    0           conv2d_55[0][0]                  \n                                                                 concatenate_24[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_55 (BatchNo (None, 1, 1, 452)    1808        concatenate_25[0][0]             \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 1, 1, 452)    0           batch_normalization_55[0][0]     \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 1, 1, 128)    57984       activation_55[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_56 (BatchNo (None, 1, 1, 128)    512         conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 1, 1, 128)    0           batch_normalization_56[0][0]     \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 1, 1, 32)     36896       activation_56[0][0]              \n__________________________________________________________________________________________________\nconcatenate_26 (Concatenate)    (None, 1, 1, 484)    0           conv2d_57[0][0]                  \n                                                                 concatenate_25[0][0]             \n__________________________________________________________________________________________________\nglobal_average_pooling2d (Globa (None, 484)          0           concatenate_26[0][0]             \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 10)           4850        global_average_pooling2d[0][0]   \n==================================================================================================\nTotal params: 2,078,926\nTrainable params: 2,056,702\nNon-trainable params: 22,224\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"callbacks = []\ntb_callback = tf.keras.callbacks.TensorBoard(args.logdir)\ncallbacks.append(tb_callback)\nif args.checkpoints_period:\n    checkpoints = tf.keras.callbacks.ModelCheckpoint('weights{epoch:08d}.h5', save_weights_only=True, period=args.checkpoints_period) \n    callbacks.append(checkpoints)\nif args.stopping_patience:\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=args.stopping_patience)\n    callbacks.append(early_stopping)\n    \ntrain_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n)\n\nlogs = model.fit(\n    train_generator.flow(\n        cifar.train.data[\"images\"],\n        cifar.train.data[\"labels\"],\n        batch_size=args.batch_size,\n        seed=args.seed,\n    ),\n    shuffle=False,\n    epochs=args.epochs,\n    validation_data=(cifar.dev.data[\"images\"], cifar.dev.data[\"labels\"]),\n    callbacks=[tb_callback, early_stopping, checkpoints],\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T13:58:19.750881Z","iopub.execute_input":"2022-03-23T13:58:19.751173Z","iopub.status.idle":"2022-03-23T14:26:54.836031Z","shell.execute_reply.started":"2022-03-23T13:58:19.751140Z","shell.execute_reply":"2022-03-23T14:26:54.835018Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/50\n352/352 [==============================] - 48s 104ms/step - loss: 2.0553 - accuracy: 0.3552 - val_loss: 1.8182 - val_accuracy: 0.4028\nEpoch 2/50\n352/352 [==============================] - 35s 99ms/step - loss: 1.6345 - accuracy: 0.4778 - val_loss: 1.7206 - val_accuracy: 0.4686\nEpoch 3/50\n352/352 [==============================] - 33s 95ms/step - loss: 1.5196 - accuracy: 0.5333 - val_loss: 1.5753 - val_accuracy: 0.5236\nEpoch 4/50\n352/352 [==============================] - 34s 96ms/step - loss: 1.4479 - accuracy: 0.5699 - val_loss: 10.9487 - val_accuracy: 0.3812\nEpoch 5/50\n352/352 [==============================] - 34s 95ms/step - loss: 1.3811 - accuracy: 0.6020 - val_loss: 1.5966 - val_accuracy: 0.5404\nEpoch 6/50\n352/352 [==============================] - 34s 97ms/step - loss: 1.3450 - accuracy: 0.6212 - val_loss: 1.4208 - val_accuracy: 0.5956\nEpoch 7/50\n352/352 [==============================] - 34s 97ms/step - loss: 1.2959 - accuracy: 0.6450 - val_loss: 1.4053 - val_accuracy: 0.5932\nEpoch 8/50\n352/352 [==============================] - 34s 96ms/step - loss: 1.2639 - accuracy: 0.6621 - val_loss: 1.2673 - val_accuracy: 0.6786\nEpoch 9/50\n352/352 [==============================] - 35s 98ms/step - loss: 1.2369 - accuracy: 0.6732 - val_loss: 1.3597 - val_accuracy: 0.6298\nEpoch 10/50\n352/352 [==============================] - 34s 96ms/step - loss: 1.2160 - accuracy: 0.6828 - val_loss: 1.3694 - val_accuracy: 0.6408\nEpoch 11/50\n352/352 [==============================] - 34s 97ms/step - loss: 1.1921 - accuracy: 0.6936 - val_loss: 1.2181 - val_accuracy: 0.6866\nEpoch 12/50\n352/352 [==============================] - 33s 95ms/step - loss: 1.1748 - accuracy: 0.7005 - val_loss: 1.2243 - val_accuracy: 0.6914\nEpoch 13/50\n352/352 [==============================] - 35s 101ms/step - loss: 1.1571 - accuracy: 0.7118 - val_loss: 1.1537 - val_accuracy: 0.7108\nEpoch 14/50\n352/352 [==============================] - 34s 96ms/step - loss: 1.1409 - accuracy: 0.7187 - val_loss: 1.2434 - val_accuracy: 0.6770\nEpoch 15/50\n352/352 [==============================] - 34s 97ms/step - loss: 1.1500 - accuracy: 0.7139 - val_loss: 1.3307 - val_accuracy: 0.6460\nEpoch 16/50\n352/352 [==============================] - 34s 98ms/step - loss: 1.1181 - accuracy: 0.7294 - val_loss: 1.2542 - val_accuracy: 0.6712\nEpoch 17/50\n352/352 [==============================] - 34s 97ms/step - loss: 1.1025 - accuracy: 0.7353 - val_loss: 1.0968 - val_accuracy: 0.7368\nEpoch 18/50\n352/352 [==============================] - 33s 93ms/step - loss: 1.0813 - accuracy: 0.7427 - val_loss: 1.2416 - val_accuracy: 0.6802\nEpoch 19/50\n352/352 [==============================] - 32s 91ms/step - loss: 1.0742 - accuracy: 0.7475 - val_loss: 1.1993 - val_accuracy: 0.7050\nEpoch 20/50\n352/352 [==============================] - 34s 97ms/step - loss: 1.0611 - accuracy: 0.7554 - val_loss: 1.0839 - val_accuracy: 0.7440\nEpoch 21/50\n352/352 [==============================] - 33s 93ms/step - loss: 1.0469 - accuracy: 0.7601 - val_loss: 1.0690 - val_accuracy: 0.7548\nEpoch 22/50\n352/352 [==============================] - 32s 92ms/step - loss: 1.0225 - accuracy: 0.7698 - val_loss: 1.0444 - val_accuracy: 0.7688\nEpoch 23/50\n352/352 [==============================] - 33s 93ms/step - loss: 1.0094 - accuracy: 0.7795 - val_loss: 1.1110 - val_accuracy: 0.7430\nEpoch 24/50\n352/352 [==============================] - 32s 92ms/step - loss: 0.9999 - accuracy: 0.7781 - val_loss: 1.1232 - val_accuracy: 0.7312\nEpoch 25/50\n352/352 [==============================] - 33s 95ms/step - loss: 0.9840 - accuracy: 0.7868 - val_loss: 1.3499 - val_accuracy: 0.6658\nEpoch 26/50\n352/352 [==============================] - 33s 94ms/step - loss: 0.9745 - accuracy: 0.7917 - val_loss: 1.0428 - val_accuracy: 0.7676\nEpoch 27/50\n352/352 [==============================] - 34s 96ms/step - loss: 0.9749 - accuracy: 0.7916 - val_loss: 0.9670 - val_accuracy: 0.7942\nEpoch 28/50\n352/352 [==============================] - 34s 96ms/step - loss: 0.9487 - accuracy: 0.8034 - val_loss: 1.0531 - val_accuracy: 0.7626\nEpoch 29/50\n352/352 [==============================] - 34s 96ms/step - loss: 0.9384 - accuracy: 0.8085 - val_loss: 0.9439 - val_accuracy: 0.8060\nEpoch 30/50\n352/352 [==============================] - 33s 94ms/step - loss: 0.9260 - accuracy: 0.8145 - val_loss: 0.9663 - val_accuracy: 0.7900\nEpoch 31/50\n352/352 [==============================] - 33s 94ms/step - loss: 0.9241 - accuracy: 0.8133 - val_loss: 1.0003 - val_accuracy: 0.7842\nEpoch 32/50\n352/352 [==============================] - 32s 91ms/step - loss: 0.9090 - accuracy: 0.8210 - val_loss: 0.9150 - val_accuracy: 0.8186\nEpoch 33/50\n352/352 [==============================] - 33s 93ms/step - loss: 0.8939 - accuracy: 0.8272 - val_loss: 0.9645 - val_accuracy: 0.7986\nEpoch 34/50\n352/352 [==============================] - 32s 91ms/step - loss: 0.8825 - accuracy: 0.8314 - val_loss: 1.0401 - val_accuracy: 0.7714\nEpoch 35/50\n352/352 [==============================] - 33s 95ms/step - loss: 0.8701 - accuracy: 0.8354 - val_loss: 0.9029 - val_accuracy: 0.8262\nEpoch 36/50\n352/352 [==============================] - 32s 91ms/step - loss: 0.8599 - accuracy: 0.8404 - val_loss: 0.8848 - val_accuracy: 0.8308\nEpoch 37/50\n352/352 [==============================] - 33s 94ms/step - loss: 0.8550 - accuracy: 0.8430 - val_loss: 0.9529 - val_accuracy: 0.8040\nEpoch 38/50\n352/352 [==============================] - 33s 94ms/step - loss: 0.8454 - accuracy: 0.8496 - val_loss: 0.9043 - val_accuracy: 0.8190\nEpoch 39/50\n352/352 [==============================] - 33s 94ms/step - loss: 0.8418 - accuracy: 0.8495 - val_loss: 0.8986 - val_accuracy: 0.8252\nEpoch 40/50\n352/352 [==============================] - 33s 92ms/step - loss: 0.8283 - accuracy: 0.8567 - val_loss: 0.8942 - val_accuracy: 0.8302\nEpoch 41/50\n352/352 [==============================] - 34s 95ms/step - loss: 0.8232 - accuracy: 0.8576 - val_loss: 0.8929 - val_accuracy: 0.8306\nEpoch 42/50\n352/352 [==============================] - 33s 93ms/step - loss: 0.8167 - accuracy: 0.8620 - val_loss: 0.8892 - val_accuracy: 0.8304\nEpoch 43/50\n352/352 [==============================] - 34s 96ms/step - loss: 0.8168 - accuracy: 0.8608 - val_loss: 0.9131 - val_accuracy: 0.8212\nEpoch 44/50\n352/352 [==============================] - 35s 98ms/step - loss: 0.8123 - accuracy: 0.8631 - val_loss: 0.8762 - val_accuracy: 0.8354\nEpoch 45/50\n352/352 [==============================] - 34s 96ms/step - loss: 0.8091 - accuracy: 0.8649 - val_loss: 0.8801 - val_accuracy: 0.8340\nEpoch 46/50\n352/352 [==============================] - 34s 96ms/step - loss: 0.8071 - accuracy: 0.8654 - val_loss: 0.8821 - val_accuracy: 0.8304\nEpoch 47/50\n352/352 [==============================] - 34s 95ms/step - loss: 0.8056 - accuracy: 0.8661 - val_loss: 0.8812 - val_accuracy: 0.8328\nEpoch 48/50\n352/352 [==============================] - 33s 93ms/step - loss: 0.8041 - accuracy: 0.8664 - val_loss: 0.8765 - val_accuracy: 0.8364\nEpoch 49/50\n352/352 [==============================] - 34s 96ms/step - loss: 0.7998 - accuracy: 0.8686 - val_loss: 0.8785 - val_accuracy: 0.8344\nEpoch 50/50\n352/352 [==============================] - 32s 90ms/step - loss: 0.7994 - accuracy: 0.8684 - val_loss: 0.8764 - val_accuracy: 0.8350\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/3641445497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtb_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"val_test_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'items'"],"ename":"AttributeError","evalue":"'History' object has no attribute 'items'","output_type":"error"}]},{"cell_type":"code","source":"os.makedirs(args.logdir, exist_ok=True)\nwith open(\n    os.path.join(args.logdir, \"cifar_competition_test.txt\"), \"w\", encoding=\"utf-8\"\n) as predictions_file:\n    for probs in model.predict(\n        cifar.test.data[\"images\"], batch_size=args.batch_size\n    ):\n        print(np.argmax(probs), file=predictions_file)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:47:59.095868Z","iopub.execute_input":"2022-03-23T14:47:59.096167Z","iopub.status.idle":"2022-03-23T14:48:00.772573Z","shell.execute_reply.started":"2022-03-23T14:47:59.096138Z","shell.execute_reply":"2022-03-23T14:48:00.771873Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}